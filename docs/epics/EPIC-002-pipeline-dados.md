# EPIC 002: Pipeline de Dados (Apify ‚Üí Supabase)

**Status**: ‚è≥ Pendente
**Prioridade**: üî¥ Cr√≠tica
**Dura√ß√£o Estimada**: 1 semana (Semana 2)
**Agente Respons√°vel**: @data-engineer + @analyst (Atlas)

---

## üéØ OBJETIVO

Implementar pipeline completo de coleta, transforma√ß√£o e carga de dados de redes sociais (Instagram, TikTok, YouTube) via Apify para Supabase.

---

## üìä CONTEXTO

Este √©pico estabelece o fluxo de dados que alimentar√° os Squads Auditores. Sem dados, n√£o h√° auditoria nem cria√ß√£o de conte√∫do.

**Depend√™ncias**:
- ‚úÖ EPIC-001 (Funda√ß√£o & Setup) - Schema Supabase + Apify MCP

**Bloqueia**:
- EPIC-003 (Squad Auditores) - Precisa dos dados para auditar
- EPIC-004 (Squad Cria√ß√£o) - Usa insights da auditoria

---

## üìã TAREFAS

###

 Task 2.1: Pesquisa de Actors Apify
**Respons√°vel**: @analyst (Atlas)
**Dura√ß√£o**: 4 horas

**Descri√ß√£o**:
Pesquisar, validar e documentar Actors do Apify para cada plataforma.

**Prompt para @analyst**:
```
Pesquisar e validar Actors do Apify:

Tarefas:
1. Instagram Profile Scraper:
   - Testar com conta real (escolher uma p√∫blica)
   - Documentar schema JSON retornado
   - Validar dados: posts, likes, comments, captions, hashtags
   - Rate limits e cr√©ditos por scrape

2. TikTok Scraper:
   - Testar com perfil p√∫blico
   - Documentar schema JSON
   - Validar: v√≠deos, views, likes, shares, trending status
   - Custos

3. YouTube Scraper:
   - Testar com canal p√∫blico
   - Validar transcri√ß√µes autom√°ticas
   - Schema de v√≠deos + estat√≠sticas
   - Custos

4. Calcular custos por cliente/m√™s:
   - Scraping semanal (4x/m√™s) de cada plataforma
   - Estimativa total de cr√©ditos Apify
   - Plano Apify recomendado

Gere documento completo com exemplos de JSON real.
```

**Crit√©rios de Aceita√ß√£o**:
- [ ] 3 Actors testados com sucesso
- [ ] Schema JSON documentado para cada
- [ ] Custos calculados por cliente/m√™s
- [ ] Rate limits identificados
- [ ] Plano Apify recomendado

**Entreg√°veis**:
- [ ] `docs/integrations/apify-actors-research.md`
- [ ] `docs/integrations/apify-instagram-schema.json` (exemplo real)
- [ ] `docs/integrations/apify-tiktok-schema.json`
- [ ] `docs/integrations/apify-youtube-schema.json`
- [ ] `docs/integrations/apify-cost-analysis.md`

---

### Task 2.2: Pipeline ETL - Apify Connector
**Respons√°vel**: @data-engineer
**Dura√ß√£o**: 1 dia

**Descri√ß√£o**:
Wrapper para Apify MCP que abstrai chamadas aos Actors.

**Especifica√ß√£o T√©cnica**:
```javascript
// src/etl/apify-connector.js

class ApifyConnector {
  async scrapeInstagram(username) {
    // Chama Apify MCP: search-actors ‚Üí call-actor ‚Üí get-actor-output
    // Retorna: { posts: [...], profile: {...}, metrics: {...} }
  }

  async scrapeTikTok(username) { /* ... */ }
  async scrapeYouTube(channelId) { /* ... */ }

  async getActorCost(actorId, runId) {
    // Retorna cr√©ditos usados
  }
}
```

**Crit√©rios de Aceita√ß√£o**:
- [ ] 3 m√©todos implementados (Instagram, TikTok, YouTube)
- [ ] Error handling robusto (timeout, rate limit, actor error)
- [ ] Retry logic com backoff exponencial
- [ ] Logging detalhado
- [ ] Testes unit√°rios (coverage > 80%)

**Entreg√°veis**:
- [ ] `src/etl/apify-connector.js`
- [ ] `src/etl/apify-connector.test.js`
- [ ] Documenta√ß√£o inline (JSDoc)

---

### Task 2.3: Pipeline ETL - Data Transformer
**Respons√°vel**: @data-engineer
**Dura√ß√£o**: 1 dia

**Descri√ß√£o**:
Transformar dados brutos dos Actors para schema Supabase.

**Especifica√ß√£o T√©cnica**:
```javascript
// src/etl/data-transformer.js

class DataTransformer {
  transformInstagramData(apifyOutput, clienteId) {
    // Apify JSON ‚Üí Schema Supabase
    return {
      auditoria: {
        cliente_id: clienteId,
        dados_brutos: apifyOutput,
        // Extrair m√©tricas agregadas
      },
      scraping_log: {
        plataforma: 'Instagram',
        status: 'success',
        creditos_usados: calculateCredits(apifyOutput)
      }
    };
  }

  transformTikTokData(apifyOutput, clienteId) { /* ... */ }
  transformYouTubeData(apifyOutput, clienteId) { /* ... */ }
}
```

**Crit√©rios de Aceita√ß√£o**:
- [ ] Transforma√ß√µes para 3 plataformas
- [ ] Valida√ß√£o de dados (schema validation)
- [ ] Normaliza√ß√£o de campos (datas, n√∫meros)
- [ ] Testes com dados reais (do Task 2.1)
- [ ] Coverage > 85%

**Entreg√°veis**:
- [ ] `src/etl/data-transformer.js`
- [ ] `src/etl/data-transformer.test.js`
- [ ] `src/etl/schemas/validation.js` (JSON Schema validation)

---

### Task 2.4: Pipeline ETL - Supabase Loader
**Respons√°vel**: @data-engineer
**Dura√ß√£o**: 1 dia

**Descri√ß√£o**:
Carregar dados transformados no Supabase com transa√ß√µes at√¥micas.

**Especifica√ß√£o T√©cnica**:
```javascript
// src/etl/supabase-loader.js

class SupabaseLoader {
  async loadAuditData(transformedData) {
    // Transaction: insert em auditorias + scraping_logs
    // Rollback se qualquer insert falhar
  }

  async loadClienteData(clienteData) { /* ... */ }

  async getLastScrapeDate(clienteId, plataforma) {
    // Para scraping incremental
  }
}
```

**Crit√©rios de Aceita√ß√£o**:
- [ ] Inserts at√¥micos (transa√ß√µes)
- [ ] Rollback em caso de erro
- [ ] Idempot√™ncia (n√£o duplicar dados)
- [ ] Batch inserts para performance
- [ ] Testes de integra√ß√£o com Supabase real

**Entreg√°veis**:
- [ ] `src/etl/supabase-loader.js`
- [ ] `src/etl/supabase-loader.test.js`
- [ ] Testes de integra√ß√£o

---

### Task 2.5: Pipeline Completo End-to-End
**Respons√°vel**: @data-engineer
**Dura√ß√£o**: 1 dia

**Descri√ß√£o**:
Orquestrar os 3 componentes (Connector ‚Üí Transformer ‚Üí Loader) em pipeline completo.

**Especifica√ß√£o T√©cnica**:
```javascript
// src/etl/pipeline.js

async function runScraping(clienteId, plataformas = ['instagram', 'tiktok', 'youtube']) {
  const connector = new ApifyConnector();
  const transformer = new DataTransformer();
  const loader = new SupabaseLoader();

  for (const plataforma of plataformas) {
    try {
      // 1. Scrape
      const rawData = await connector.scrape(plataforma, clienteUsername);

      // 2. Transform
      const transformed = transformer.transform(plataforma, rawData, clienteId);

      // 3. Load
      await loader.load(transformed);

      // 4. Log success
      console.log(`‚úÖ ${plataforma} scraping complete`);
    } catch (error) {
      // Log error mas continua outras plataformas
      console.error(`‚ùå ${plataforma} failed:`, error);
    }
  }
}
```

**Crit√©rios de Aceita√ß√£o**:
- [ ] Pipeline completo funciona para 3 plataformas
- [ ] Error handling n√£o quebra todo o pipeline
- [ ] Logs estruturados
- [ ] CLI para rodar manualmente: `npm run scrape -- --cliente=123`
- [ ] Scheduler b√°sico (cron) para scraping semanal

**Entreg√°veis**:
- [ ] `src/etl/pipeline.js`
- [ ] `scripts/run-scraping.js` (CLI)
- [ ] `scripts/schedule-scraping.js` (cron setup)
- [ ] Teste end-to-end com 1 cliente real

---

## üö¶ GATE DE QUALIDADE

**Crit√©rios para considerar EPIC-002 completo**:

### T√©cnicos:
- [ ] Pipeline completo funciona (Apify ‚Üí Supabase)
- [ ] 3 plataformas testadas com dados reais
- [ ] Error handling robusto (nenhum crash)
- [ ] Performance aceit√°vel (< 2 min por plataforma)
- [ ] Tests coverage > 80%

### Code Review (@architect):
- [ ] Arquitetura aprovada
- [ ] Separa√ß√£o de responsabilidades (SRP)
- [ ] Error handling em todas as camadas
- [ ] C√≥digo documentado

### QA (@qa):
- [ ] Testes passando (unit + integration)
- [ ] Edge cases cobertos (rate limit, timeout, dados inv√°lidos)
- [ ] Scraping testado com 3 contas reais
- [ ] Dados no Supabase validados (schema correto, sem duplicatas)

---

## üìä M√âTRICAS DE SUCESSO

| M√©trica | Meta | Como Medir |
|---------|------|------------|
| Tempo de scraping | < 2 min/plataforma | Logs do pipeline |
| Taxa de sucesso | > 95% | scraping_logs.status |
| Cr√©ditos Apify | < $3.50/cliente/m√™s | Estimativa validada |
| Coverage de testes | > 80% | Jest coverage report |

---

## üîó DEPEND√äNCIAS EXTERNAS

### APIs:
- Apify MCP (via Docker)
- Supabase (dev environment)

### Dados de Teste:
- 3 contas p√∫blicas (Instagram, TikTok, YouTube)
- Exemplos de JSON real dos Actors

---

## üìù NOTAS

- **Prioridade em robustez**: Pipeline deve lidar com falhas sem quebrar
- **Custo**: Monitorar cr√©ditos Apify durante testes
- **Rate Limits**: Implementar retry com backoff exponencial
- **Dados sens√≠veis**: Nunca commitar usernames reais ou chaves API

---

## üéØ PR√ìXIMO PASSO

Ap√≥s completar EPIC-002:
‚Üí **EPIC-003: Squad Auditores**
(Agora com dados reais para auditar!)

---

**Criado por**: @pm (Morgan)
**Data**: 2026-02-16
**Vers√£o**: 1.0
